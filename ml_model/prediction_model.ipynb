{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "kveUfVypCm8B",
        "y-NemLv4GrHy",
        "hthbLrchb2GS",
        "dYKEd_6AoVeS",
        "OAFlGbOV3U5t"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DgQiq2ZoTSuw",
        "outputId": "9c31e8e6-ccb0-486a-e5a3-d14da38b395f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stock Market Data"
      ],
      "metadata": {
        "id": "kveUfVypCm8B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import yfinance as yf\n",
        "\n",
        "def download_stock_data(ticker, start, end, interval=\"1d\"):\n",
        "  df = yf.download(ticker, start=start, end=end, interval=interval)\n",
        "  return df"
      ],
      "metadata": {
        "id": "4fxZ7pApP-bd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRo80Xb6B-F8",
        "outputId": "a4d3315e-e451-4099-be79-298ce48625b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Price            Close        High         Low        Open    Volume\n",
            "Ticker            TSLA        TSLA        TSLA        TSLA      TSLA\n",
            "Date                                                                \n",
            "2021-09-30  258.493347  263.043335  258.333344  260.333344  53868000\n",
            "2021-10-01  258.406677  260.260010  254.529999  259.466675  51094200\n",
            "2021-10-04  260.510010  268.989990  258.706665  265.500000  91449900\n",
            "2021-10-05  260.196655  265.769989  258.066681  261.600006  55297800\n",
            "2021-10-06  260.916656  262.220001  257.739990  258.733337  43898400\n",
            "...                ...         ...         ...         ...       ...\n",
            "2022-09-22  288.589996  301.290009  285.820007  299.859985  70545400\n",
            "2022-09-23  275.329987  284.500000  272.820007  283.089996  63748400\n",
            "2022-09-26  276.010010  284.089996  270.309998  271.829987  58076900\n",
            "2022-09-27  282.940002  288.670013  277.510010  283.839996  61925200\n",
            "2022-09-28  287.809998  289.000000  277.570007  283.079987  54664800\n",
            "\n",
            "[251 rows x 5 columns]\n"
          ]
        }
      ],
      "source": [
        "stock_ticker = \"TSLA\"\n",
        "start_date = \"2021-09-30\"\n",
        "end_date = \"2022-09-29\"\n",
        "\n",
        "stock_market_df = download_stock_data(stock_ticker, start_date, end_date)\n",
        "\n",
        "save_path = '/content/drive/MyDrive/SDP-FINAL/TSLA_stock_data.csv'\n",
        "\n",
        "stock_market_df.to_csv(save_path)\n",
        "\n",
        "print()\n",
        "print(stock_market_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Social Media Data"
      ],
      "metadata": {
        "id": "y-NemLv4GrHy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the CSV file\n",
        "file_path = \"/content/drive/MyDrive/SDP-FINAL/kaggle_tweets.csv\"  # Update with the correct file path\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Convert the 'Date' column to datetime format\n",
        "df['Date'] = pd.to_datetime(df['Date'])\n",
        "\n",
        "# Filter out rows where the date is <= 2021-12-30\n",
        "filtered_df = df[(df['Date'] > '2021-09-29') & (df['Stock Name'] == 'TSLA')]\n",
        "\n",
        "filtered_df['Date'] = filtered_df['Date'].dt.date\n",
        "\n",
        "filtered_file_path = \"/content/drive/MyDrive/SDP-FINAL/TSLA_tweets.csv\"  # Update as needed\n",
        "filtered_df.to_csv(filtered_file_path, index=False)\n",
        "\n",
        "print(\"Filtered data saved to:\", filtered_file_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KAVG7X3hGvKK",
        "outputId": "c9a7cbc2-97cc-45fa-8625-e673365cac38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-36-374d473d6ce5>:13: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  filtered_df['Date'] = filtered_df['Date'].dt.date\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtered data saved to: /content/drive/MyDrive/SDP-FINAL/TSLA_tweets.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sentiment Analysis"
      ],
      "metadata": {
        "id": "hthbLrchb2GS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install vaderSentiment\n",
        "\n",
        "import pandas as pd\n",
        "import re\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "\n",
        "# Initialize the VADER sentiment analyzer\n",
        "analyzer = SentimentIntensityAnalyzer()"
      ],
      "metadata": {
        "id": "pFFlWIhye1l1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "629af42f-3115-4080-e7a1-94df7fd66b38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: vaderSentiment in /usr/local/lib/python3.11/dist-packages (3.3.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from vaderSentiment) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->vaderSentiment) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->vaderSentiment) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->vaderSentiment) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->vaderSentiment) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to get the sentiment label based on compound score\n",
        "def get_sentiment_label(tweet):\n",
        "    compound_score = analyzer.polarity_scores(tweet)['compound']\n",
        "    if compound_score >= 0.05:\n",
        "        return 'Positive'\n",
        "    elif compound_score <= -0.05:\n",
        "        return 'Negative'\n",
        "    else:\n",
        "        return 'Neutral'"
      ],
      "metadata": {
        "id": "RW71jzU7e2sG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text).lower()\n",
        "    return text"
      ],
      "metadata": {
        "id": "wRT_vqIIe7R6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_csv_path = '/content/drive/MyDrive/SDP-FINAL/TSLA_tweets.csv'  # Update with your CSV file path\n",
        "df = pd.read_csv(input_csv_path)\n",
        "\n",
        "# Display the first few rows to check the structure\n",
        "print(df.head())\n",
        "\n",
        "# Add the Sentiment column\n",
        "df['Tweet'] = df['Tweet'].apply(lambda tweet: clean_text(tweet))\n",
        "df['Sentiment'] = df['Tweet'].apply(lambda tweet: get_sentiment_label(tweet))\n",
        "\n",
        "# Save the updated DataFrame to a new CSV file\n",
        "output_csv_path = '/content/drive/MyDrive/SDP-FINAL/TSLA_sentiment_tweets.csv'\n",
        "df.to_csv(output_csv_path, index=False)\n",
        "\n",
        "print(f\"Sentiment analysis complete. Data saved to {output_csv_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAzmpRddb1qk",
        "outputId": "74b5f659-c99b-430a-ca6c-1b36a20e3341"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         Date                                              Tweet Stock Name  \\\n",
            "0  2022-09-29  Mainstream media has done an amazing job at br...       TSLA   \n",
            "1  2022-09-29  Tesla delivery estimates are at around 364k fr...       TSLA   \n",
            "2  2022-09-29  3/ Even if I include 63.0M unvested RSUs as of...       TSLA   \n",
            "3  2022-09-29  @RealDanODowd @WholeMarsBlog @Tesla Hahaha why...       TSLA   \n",
            "4  2022-09-29  @RealDanODowd @Tesla Stop trying to kill kids,...       TSLA   \n",
            "\n",
            "  Company Name  \n",
            "0  Tesla, Inc.  \n",
            "1  Tesla, Inc.  \n",
            "2  Tesla, Inc.  \n",
            "3  Tesla, Inc.  \n",
            "4  Tesla, Inc.  \n",
            "Sentiment analysis complete. Data saved to /content/drive/MyDrive/SDP-FINAL/TSLA_sentiment_tweets.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Merge both dataset"
      ],
      "metadata": {
        "id": "iYoMbb255SKF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load datasets\n",
        "tweets_file_path = \"/content/drive/MyDrive/SDP-FINAL/TSLA_sentiment_tweets.csv\"\n",
        "stock_file_path = \"/content/drive/MyDrive/SDP-FINAL/TSLA_stock_data.csv\"\n",
        "\n",
        "tweets_df = pd.read_csv(tweets_file_path)\n",
        "stock_df = pd.read_csv(stock_file_path, skiprows=1)  # Skip first row if necessary\n",
        "\n",
        "# Rename stock columns\n",
        "stock_df.columns = [\"Date\", \"Close Price\", \"High Price\", \"Low Price\", \"Open Price\", \"Trading Volume\"]\n",
        "\n",
        "# Convert date columns to datetime format\n",
        "tweets_df[\"Date\"] = pd.to_datetime(tweets_df[\"Date\"], errors='coerce')\n",
        "stock_df[\"Date\"] = pd.to_datetime(stock_df[\"Date\"], errors='coerce')\n",
        "\n",
        "# Convert stock price columns to numeric\n",
        "for col in [\"Close Price\", \"High Price\", \"Low Price\", \"Open Price\", \"Trading Volume\"]:\n",
        "    stock_df[col] = pd.to_numeric(stock_df[col], errors='coerce')\n",
        "\n",
        "# Map sentiment to numerical values\n",
        "sentiment_mapping = {\"Positive\": 1, \"Neutral\": 0, \"Negative\": -1}\n",
        "tweets_df[\"Sentiment Score\"] = tweets_df[\"Sentiment\"].map(sentiment_mapping)\n",
        "\n",
        "# Aggregate tweets per date\n",
        "tweets_agg = tweets_df.groupby(\"Date\").agg(\n",
        "    Tweet_Count=(\"Sentiment Score\", \"count\"),\n",
        "    Avg_Tweet_Sentiment=(\"Sentiment Score\", \"mean\")\n",
        ").reset_index()\n",
        "\n",
        "# Merge tweets and stock data\n",
        "merged_df = pd.merge(stock_df, tweets_agg, on=\"Date\", how=\"left\")\n",
        "\n",
        "# Fill missing Tweet data by propagating previous day's values\n",
        "merged_df[\"Tweet_Count\"].fillna(method=\"ffill\", inplace=True)\n",
        "merged_df[\"Avg_Tweet_Sentiment\"].fillna(method=\"ffill\", inplace=True)\n",
        "\n",
        "# Compute target label (1 = Up, 0 = Down)\n",
        "merged_df[\"Next Day Close Price\"] = merged_df[\"Close Price\"].shift(-1)\n",
        "merged_df[\"Stock Movement\"] = (merged_df[\"Next Day Close Price\"] > merged_df[\"Close Price\"]).astype(int)\n",
        "\n",
        "# Drop extra column\n",
        "merged_df.drop(columns=[\"Next Day Close Price\"], inplace=True)\n",
        "\n",
        "# Save the final dataset\n",
        "merged_df.to_csv(\"/content/drive/MyDrive/SDP-FINAL/TSLA_dataset.csv\", index=False)\n",
        "\n",
        "print(\"Merged dataset saved as merged_tesla_data.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x90BLdM82eA1",
        "outputId": "ab463b9e-3313-4f97-d637-ea8eb1e74ead"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Merged dataset saved as merged_tesla_data.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-41-c3fe85ff7804>:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  stock_df[\"Date\"] = pd.to_datetime(stock_df[\"Date\"], errors='coerce')\n",
            "<ipython-input-41-c3fe85ff7804>:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  merged_df[\"Tweet_Count\"].fillna(method=\"ffill\", inplace=True)\n",
            "<ipython-input-41-c3fe85ff7804>:37: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  merged_df[\"Tweet_Count\"].fillna(method=\"ffill\", inplace=True)\n",
            "<ipython-input-41-c3fe85ff7804>:38: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  merged_df[\"Avg_Tweet_Sentiment\"].fillna(method=\"ffill\", inplace=True)\n",
            "<ipython-input-41-c3fe85ff7804>:38: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  merged_df[\"Avg_Tweet_Sentiment\"].fillna(method=\"ffill\", inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing"
      ],
      "metadata": {
        "id": "dYKEd_6AoVeS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the CSV file\n",
        "file_path = \"/content/drive/MyDrive/SDP-ML/stock_tweets.csv\"  # Update with the correct file path\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Convert the 'Date' column to datetime format\n",
        "df['Date'] = pd.to_datetime(df['Date'])\n",
        "\n",
        "# Filter out rows where the date is <= 2021-12-30\n",
        "filtered_df = df[(df['Date'] > '2021-09-29') & (df['Stock Name'] == 'TSLA')]\n",
        "\n",
        "filtered_df['Date'] = filtered_df['Date'].dt.date\n",
        "\n",
        "filtered_file_path = \"/content/drive/MyDrive/SDP-ML/temp.csv\"  # Update as needed\n",
        "filtered_df.to_csv(filtered_file_path, index=False)\n",
        "\n",
        "print(\"Filtered data saved to:\", filtered_file_path)\n"
      ],
      "metadata": {
        "id": "N0x9zZDloU_h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ec30787-afde-4ca0-d1c4-c6eeb6358dba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-e262ea1740be>:13: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  filtered_df['Date'] = filtered_df['Date'].dt.date\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtered data saved to: /content/drive/MyDrive/SDP-ML/temp.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# add class label\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Load the CSV file\n",
        "file_path = \"/content/drive/MyDrive/SDP-ML/merged_tesla_data.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Ensure the data is sorted by date\n",
        "df = df.sort_values(by=\"Date\").reset_index(drop=True)\n",
        "\n",
        "# Create the 'Class' column based on the given condition\n",
        "df['Class'] = (df['Stock Close Price'].shift(-1) > df['Stock Close Price']).astype(int)\n",
        "\n",
        "# Save the modified DataFrame\n",
        "output_path = \"/content/drive/MyDrive/SDP-ML/final_telsa_data.csv\"\n",
        "df.to_csv(output_path, index=False)\n",
        "\n",
        "print(f\"Modified file saved to: {output_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFIoAyaVLy75",
        "outputId": "2543a46a-b0d1-4be9-9a42-997ed9bf8cad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modified file saved to: /content/drive/MyDrive/SDP-ML/final_telsa_data.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# merge dataset\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Load datasets\n",
        "tweets_file_path = \"/content/drive/MyDrive/SDP-ML/TSLA_sentiment_tweets.csv\"\n",
        "stock_file_path = \"/content/drive/MyDrive/SDP-ML/TSLA_data.csv\"\n",
        "\n",
        "tweets_df = pd.read_csv(tweets_file_path)\n",
        "stock_df = pd.read_csv(stock_file_path, skiprows=1)  # Skip first row if necessary\n",
        "\n",
        "# Rename stock columns\n",
        "stock_df.columns = [\"Date\", \"Stock Close Price\", \"Stock High Price\", \"Stock Low Price\", \"Stock Open Price\", \"Stock Trading Volume\"]\n",
        "\n",
        "# Convert date columns to datetime format\n",
        "tweets_df[\"Date\"] = pd.to_datetime(tweets_df[\"Date\"], errors='coerce')\n",
        "stock_df[\"Date\"] = pd.to_datetime(stock_df[\"Date\"], errors='coerce')\n",
        "\n",
        "# Convert stock price columns to numeric\n",
        "for col in [\"Stock Close Price\", \"Stock High Price\", \"Stock Low Price\", \"Stock Open Price\", \"Stock Trading Volume\"]:\n",
        "    stock_df[col] = pd.to_numeric(stock_df[col], errors='coerce')\n",
        "\n",
        "# Map sentiment to numerical values\n",
        "sentiment_mapping = {\"Positive\": 1, \"Neutral\": 0, \"Negative\": -1}\n",
        "tweets_df[\"Sentiment Score\"] = tweets_df[\"Sentiment\"].map(sentiment_mapping)\n",
        "\n",
        "# Aggregate tweets per date\n",
        "tweets_agg = tweets_df.groupby(\"Date\").agg(\n",
        "    Tweet_Count=(\"Sentiment Score\", \"count\"),\n",
        "    Avg_Tweet_Sentiment=(\"Sentiment Score\", \"mean\")\n",
        ").reset_index()\n",
        "\n",
        "# Merge tweets and stock data\n",
        "merged_df = pd.merge(stock_df, tweets_agg, on=\"Date\", how=\"left\")\n",
        "\n",
        "# Fill missing Tweet data by propagating previous day's values\n",
        "merged_df[\"Tweet_Count\"].fillna(method=\"ffill\", inplace=True)\n",
        "merged_df[\"Avg_Tweet_Sentiment\"].fillna(method=\"ffill\", inplace=True)\n",
        "\n",
        "# Compute target label (1 = Up, 0 = Down)\n",
        "merged_df[\"Next Day Close Price\"] = merged_df[\"Stock Close Price\"].shift(-1)\n",
        "merged_df[\"Stock Movement\"] = (merged_df[\"Next Day Close Price\"] > merged_df[\"Stock Close Price\"]).astype(int)\n",
        "\n",
        "# Drop extra column\n",
        "merged_df.drop(columns=[\"Next Day Close Price\"], inplace=True)\n",
        "\n",
        "# Save the final dataset\n",
        "merged_df.to_csv(\"/content/drive/MyDrive/SDP-ML/final.csv\", index=False)\n",
        "\n",
        "print(\"Merged dataset saved as merged_tesla_data.csv\")\n"
      ],
      "metadata": {
        "id": "756HrOM7L2Gz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cffd560f-5327-4399-c670-b021eeb0ad23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Merged dataset saved as merged_tesla_data.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-30-5a2bbe4bb6da>:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  stock_df[\"Date\"] = pd.to_datetime(stock_df[\"Date\"], errors='coerce')\n",
            "<ipython-input-30-5a2bbe4bb6da>:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  merged_df[\"Tweet_Count\"].fillna(method=\"ffill\", inplace=True)\n",
            "<ipython-input-30-5a2bbe4bb6da>:37: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  merged_df[\"Tweet_Count\"].fillna(method=\"ffill\", inplace=True)\n",
            "<ipython-input-30-5a2bbe4bb6da>:38: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  merged_df[\"Avg_Tweet_Sentiment\"].fillna(method=\"ffill\", inplace=True)\n",
            "<ipython-input-30-5a2bbe4bb6da>:38: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  merged_df[\"Avg_Tweet_Sentiment\"].fillna(method=\"ffill\", inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Model Using LogisticRegression"
      ],
      "metadata": {
        "id": "OAFlGbOV3U5t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Load dataset\n",
        "file_path = \"/content/drive/MyDrive/SDP-FINAL/TSLA_dataset.csv\"  # Update this path if needed\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Handle missing values (if any)\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# Define features (X) and target (y)\n",
        "X = df.drop(columns=[\"Stock Movement\", \"Date\"])  # Exclude target & non-numeric columns\n",
        "y = df[\"Stock Movement\"]  # Target column (0 = Down, 1 = Up)\n",
        "\n",
        "# Feature Scaling\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Train-Test Split (80-20)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Train Logistic Regression Model\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Model Evaluation\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "# Print Results\n",
        "print(f\"Model Accuracy: {accuracy:.4f}\")\n",
        "print(\"Classification Report:\\n\", report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "obwFKFhzoY7m",
        "outputId": "a54bc84c-7bb7-44c6-8170-da53592486b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 0.4706\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.41      0.29      0.34        24\n",
            "           1       0.50      0.63      0.56        27\n",
            "\n",
            "    accuracy                           0.47        51\n",
            "   macro avg       0.46      0.46      0.45        51\n",
            "weighted avg       0.46      0.47      0.46        51\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Model using RandomForestClassifier"
      ],
      "metadata": {
        "id": "wC4f64sK4I8-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('/content/drive/MyDrive/SDP-FINAL/TSLA_dataset.csv')\n",
        "\n",
        "# Drop the first row if it contains NaN values\n",
        "df = df.dropna().reset_index(drop=True)\n",
        "\n",
        "# Rename columns for consistency\n",
        "df.rename(columns={\n",
        "    'Close Price': 'Close',\n",
        "    'High Price': 'High',\n",
        "    'Low Price': 'Low',\n",
        "    'Open Price': 'Open',\n",
        "    'Trading Volume': 'Volume',\n",
        "    'Avg_Tweet_Sentiment': 'Sentiment_Score',\n",
        "    'Stock Movement': 'Target'\n",
        "}, inplace=True)\n",
        "\n",
        "# Calculate the percentage change in the closing price\n",
        "df['Close_pct_change'] = df['Close'].pct_change()\n",
        "\n",
        "# Shift the 'Close_pct_change' to create the target variable\n",
        "df['Target'] = df['Close_pct_change'].shift(-1)\n",
        "df['Target'] = np.where(df['Target'] > 0, 1, 0)  # 1 if price goes up, 0 otherwise\n",
        "\n",
        "# Drop the last row (because the target is NaN)\n",
        "df = df.iloc[:-1]\n",
        "\n",
        "# Feature Selection\n",
        "features = ['Sentiment_Score', 'Open', 'High', 'Low', 'Close', 'Volume', 'Close_pct_change']\n",
        "target = 'Target'\n",
        "X = df[features]\n",
        "y = df[target]\n",
        "\n",
        "# Handle NaN values (optional - depending on your data)\n",
        "X = X.fillna(method='ffill')  # Forward fill for simplicity\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train the model\n",
        "model = RandomForestClassifier(random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Example of how to predict using new data\n",
        "new_data = pd.DataFrame({\n",
        "    'Sentiment_Score': [0.2],\n",
        "    'Open': [100],\n",
        "    'High': [102],\n",
        "    'Low': [98],\n",
        "    'Close': [101],\n",
        "    'Volume': [100000],\n",
        "    'Close_pct_change': [0.01]  # Replace with an actual value\n",
        "})\n",
        "\n",
        "prediction = model.predict(new_data)[0]\n",
        "print(f\"Prediction: {prediction} (1: Up, 0: Down)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJtsXHQS4NrW",
        "outputId": "0a06975c-603d-4e4c-a6b6-bfa434af64d6"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-48-4542689e14d1>:41: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  X = X.fillna(method='ffill')  # Forward fill for simplicity\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5600\n",
            "Prediction: 1 (1: Up, 0: Down)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Model using RandomForestRegressor"
      ],
      "metadata": {
        "id": "T-JCXYif45l0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, accuracy_score\n",
        "import xgboost as xgb\n",
        "\n",
        "# Load the dataset\n",
        "# df = pd.read_csv('merged_tesla_data.csv')\n",
        "df = pd.read_csv('/content/drive/MyDrive/SDP-FINAL/TSLA_dataset.csv')\n",
        "\n",
        "# Drop the first row if it contains NaN values\n",
        "df = df.dropna().reset_index(drop=True)\n",
        "\n",
        "# Rename columns for consistency\n",
        "df.rename(columns={\n",
        "    'Close Price': 'Close',\n",
        "    'High Price': 'High',\n",
        "    'Low Price': 'Low',\n",
        "    'Open Price': 'Open',\n",
        "    'Trading Volume': 'Volume',\n",
        "    'Avg_Tweet_Sentiment': 'Sentiment_Score',\n",
        "    'Stock Movement': 'Target'\n",
        "}, inplace=True)\n",
        "\n",
        "# Feature Engineering\n",
        "df['MA5'] = df['Close'].rolling(window=5).mean()\n",
        "df['MA20'] = df['Close'].rolling(window=20).mean()\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# Define target variable based on close price change\n",
        "df['Target'] = np.where(df['Close'].pct_change() > 0.005, 1, 0)\n",
        "\n",
        "# Define features and target variables\n",
        "features = ['Sentiment_Score', 'Open', 'High', 'Low', 'Volume', 'MA5', 'MA20']\n",
        "X = df[features]\n",
        "y_direction = df['Target']  # Target for direction prediction\n",
        "y_price = df['Close']  # Target for price prediction\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train_dir, X_test_dir, y_train_dir, y_test_dir = train_test_split(X, y_direction, test_size=0.1, random_state=42)\n",
        "X_train_price, X_test_price, y_train_price, y_test_price = train_test_split(X, y_price, test_size=0.1, random_state=42)\n",
        "\n",
        "# Train the direction prediction model (XGBoost Classifier)\n",
        "model_direction = xgb.XGBClassifier()\n",
        "model_direction.fit(X_train_dir, y_train_dir)\n",
        "\n",
        "# Train the price prediction model (RandomForestRegressor)\n",
        "model_price = RandomForestRegressor(random_state=42)\n",
        "model_price.fit(X_train_price, y_train_price)\n",
        "\n",
        "# Evaluate the models\n",
        "y_pred_direction = model_direction.predict(X_test_dir)\n",
        "direction_accuracy = accuracy_score(y_test_dir, y_pred_direction)\n",
        "print(f\"Direction prediction accuracy: {direction_accuracy:.2f}\")\n",
        "\n",
        "y_pred_price = model_price.predict(X_test_price)\n",
        "price_rmse = np.sqrt(mean_squared_error(y_test_price, y_pred_price))\n",
        "print(f\"Price prediction RMSE: {price_rmse:.2f}\")\n",
        "\n",
        "# # Example Prediction (replace with actual new data)\n",
        "new_data = X.iloc[-1].copy()\n",
        "new_data['Sentiment_Score'] = 0.2\n",
        "new_data = pd.DataFrame([new_data])\n",
        "\n",
        "# Predict the stock movement for next day\n",
        "price_prediction = model_price.predict(new_data)\n",
        "direction_prediction = model_direction.predict(new_data)[0]\n",
        "\n",
        "print(f\"Predicted Price: {price_prediction[0]:.2f}\")\n",
        "print(f\"Predicted Direction: {'Up' if direction_prediction == 1 else 'Down'}\")\n",
        "\n",
        "# Test on one data point (from test set)\n",
        "test_index = 20  # Select first test sample\n",
        "test_data = X_test_price.iloc[[test_index]]\n",
        "test_actual_price = y_test_price.iloc[test_index]\n",
        "test_actual_direction = y_test_dir.iloc[test_index]\n",
        "\n",
        "test_predicted_price = model_price.predict(test_data)[0]\n",
        "test_predicted_direction = model_direction.predict(test_data)[0]\n",
        "\n",
        "print(\"\\nTest Data Input:\")\n",
        "print(test_data)\n",
        "print(\"\\nActual Output:\")\n",
        "print(f\"Actual Price: {test_actual_price:.2f}\")\n",
        "print(f\"Actual Direction: {'Up' if test_actual_direction == 1 else 'Down'}\")\n",
        "print(\"\\nPredicted Output:\")\n",
        "print(f\"Predicted Price: {test_predicted_price:.2f}\")\n",
        "print(f\"Predicted Direction: {'Up' if test_predicted_direction == 1 else 'Down'}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MiObaKuT47U9",
        "outputId": "c21a26d3-6f74-47f3-bd56-daa6e709b873"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Direction prediction accuracy: 0.54\n",
            "Price prediction RMSE: 4.53\n",
            "Predicted Price: 285.94\n",
            "Predicted Direction: Up\n",
            "\n",
            "Test Data Input:\n",
            "     Sentiment_Score        Open        High         Low      Volume  \\\n",
            "127         0.097345  360.383331  364.916656  355.546661  54263100.0   \n",
            "\n",
            "            MA5        MA20  \n",
            "127  363.172668  311.557999  \n",
            "\n",
            "Actual Output:\n",
            "Actual Price: 361.53\n",
            "Actual Direction: Up\n",
            "\n",
            "Predicted Output:\n",
            "Predicted Price: 361.61\n",
            "Predicted Direction: Down\n"
          ]
        }
      ]
    }
  ]
}